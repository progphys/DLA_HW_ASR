{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c4622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/progphys/asr-hw/f8fff82d17f34cebbcb0db9b4c3801c6\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : smoke-test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/progphys/asr-hw/f8fff82d17f34cebbcb0db9b4c3801c6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_demo              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps_per_sec_demo [4] : (52.87368476709142, 8000.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : smoke-test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     note                : smoke\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer|resume_from : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     audio               : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataframe           : 1 (17 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 8.6291738e-02  1.7193973e-01  3.3875823e-01]\n",
      " [ 1.7193973e-01  3.3875823e-01  6.3745725e-01]\n",
      " ...\n",
      " [-1.7185840e-01 -3.3860287e-01 -6.3720274e-01]\n",
      " [-8.6304612e-02 -1.7196518e-01 -3.3880684e-01]\n",
      " [ 1.3670491e-05  2.7340982e-05  5.4681965e-05]]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from src.logger.cometml import CometMLWriter\n",
    "logger = logging.getLogger(\"smoke\")\n",
    "project_config = {\"trainer\": {\"resume_from\": None}, \"note\": \"smoke\"}\n",
    "writer = CometMLWriter(\n",
    "    logger=logger,\n",
    "    project_config=project_config,\n",
    "    project_name=\"asr-hw\",\n",
    "    workspace=\"progphys\",\n",
    "    run_name=\"smoke-test\",\n",
    "    mode=\"online\",\n",
    ")\n",
    "\n",
    "writer.set_step(0, mode=\"demo\")\n",
    "writer.add_scalar(\"loss\", 1.0)\n",
    "\n",
    "writer.set_step(1, mode=\"demo\")\n",
    "writer.add_image(\"img\", (np.random.rand(32, 64) * 255).astype(np.uint8))\n",
    "\n",
    "sr = 16000\n",
    "t = torch.linspace(0, 1, sr)\n",
    "\n",
    "audio_3ch_torch = torch.stack([\n",
    "    torch.sin(2 * torch.pi * 220 * t),\n",
    "    torch.sin(2 * torch.pi * 440 * t),\n",
    "    torch.sin(2 * torch.pi * 880 * t),\n",
    "], dim=0) \n",
    "\n",
    "writer.set_step(2, mode=\"demo\")\n",
    "writer.add_audio(\"sine_3ch_torch\", audio_3ch_torch, sample_rate=sr)\n",
    "\n",
    "t_np = np.linspace(0, 1, sr, endpoint=False)\n",
    "audio_3ch_np = np.stack([\n",
    "    np.sin(2 * np.pi * 220 * t_np),\n",
    "    np.sin(2 * np.pi * 440 * t_np),\n",
    "    np.sin(2 * np.pi * 880 * t_np),\n",
    "], axis=1).astype(np.float32)   \n",
    "\n",
    "\n",
    "writer.set_step(3, mode=\"demo\")\n",
    "writer.add_audio(\"sine_3ch_numpy\", audio_3ch_np, sample_rate=sr)\n",
    "\n",
    "\n",
    "writer.set_step(4, mode=\"demo\")\n",
    "writer.add_audio(\"from_file_3ch\", \"test.wav\")\n",
    "\n",
    "writer.add_text(\"pred\", \"hello\")\n",
    "writer.add_histogram(\"h\", torch.randn(1000))\n",
    "\n",
    "writer.add_table(\"t\", pd.DataFrame({\"a\":[1,2], \"b\":[3,4]}))\n",
    "\n",
    "writer.exp.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3904b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcd\n",
      "bbcccd\n"
     ]
    }
   ],
   "source": [
    "#check ctc decode\n",
    "\n",
    "from src.text_encoder.ctc_text_encoder import CTCTextEncoder\n",
    "\n",
    "model = CTCTextEncoder()\n",
    "fake_inds = torch.tensor([0, 2, 2, 0, 3, 3, 3, 0, 4], dtype=torch.long)\n",
    "print(model.ctc_decode(fake_inds))\n",
    "print(model.decode(fake_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78424582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics.utils import calc_cer,calc_wer\n",
    "#chatgpt generate tests\n",
    "eps = 1e-6\n",
    "\n",
    "tests = [\n",
    "    (\"\", \"\", 0.0, 0.0),\n",
    "    (\"\", \"a\", 1.0, 1.0),\n",
    "    (\"abcd\", \"aecd\", 0.25, 1.0),\n",
    "    (\"abcd\", \"\", 1.0, 1.0),\n",
    "    (\"abcd\", \"abbcd\", 0.25, 1.0),\n",
    "    (\"a b c\", \"a b\", None, 1/3),\n",
    "    (\"a b\", \"a x b\", None, 0.5),\n",
    "]\n",
    "\n",
    "for t, p, cer_exp, wer_exp in tests:\n",
    "    cer = calc_cer(t, p)\n",
    "    wer = calc_wer(t, p)\n",
    "\n",
    "    if cer_exp is not None:\n",
    "        assert abs(cer - cer_exp) < eps, (t, p, cer, cer_exp)\n",
    "\n",
    "    if wer_exp is not None:\n",
    "        assert abs(wer - wer_exp) < eps, (t, p, wer, wer_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ec22fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/humtech/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/humtech/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "InstantiationException",
     "evalue": "Error locating target 'torchvision.transforms.v2.Compose', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: train.audio",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/utils.py:635\u001b[39m, in \u001b[36m_locate\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m635\u001b[39m     obj = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1204\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1176\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1147\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:690\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:940\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:241\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/torchvision/__init__.py:10\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/torchvision/_meta_registrations.py:25\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;129;43m@register_meta\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mroi_align\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_roi_align\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspatial_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooled_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maligned\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrois\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrois must have shape as Tensor[K, 5]\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/torchvision/_meta_registrations.py:18\u001b[39m, in \u001b[36mregister_meta.<locals>.wrapper\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(fn):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorchvision\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextension\u001b[49m._has_ops():\n\u001b[32m     19\u001b[39m         get_meta_lib().impl(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(torch.ops.torchvision, op_name), overload_name), fn)\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:134\u001b[39m, in \u001b[36m_resolve_target\u001b[39m\u001b[34m(target, full_key)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     target = \u001b[43m_locate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/utils.py:637\u001b[39m, in \u001b[36m_locate\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc_import:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    638\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError loading \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(exc_import)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    639\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAre you sure that module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is installed?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    640\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc_import\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(parts)):\n",
      "\u001b[31mImportError\u001b[39m: Error loading 'torchvision.transforms.v2.Compose':\nAttributeError(\"partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)\")\nAre you sure that module 'torchvision' is installed?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mInstantiationException\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m datasets_cfg = OmegaConf.load(\u001b[33m\"\u001b[39m\u001b[33msrc/configs/datasets/onebatchtest.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m instance_tf_cfg = OmegaConf.load(\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msrc/configs/transforms/instance_transforms/example.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m instance_transforms_train = \u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minstance_tf_cfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m}\u001b[49m\n\u001b[32m     16\u001b[39m instance_transforms_infer = {\n\u001b[32m     17\u001b[39m     k: instantiate(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m instance_tf_cfg.inference.items()\n\u001b[32m     18\u001b[39m }\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      7\u001b[39m datasets_cfg = OmegaConf.load(\u001b[33m\"\u001b[39m\u001b[33msrc/configs/datasets/onebatchtest.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m instance_tf_cfg = OmegaConf.load(\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msrc/configs/transforms/instance_transforms/example.yaml\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m instance_transforms_train = {\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     k: \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m instance_tf_cfg.train.items()\n\u001b[32m     14\u001b[39m }\n\u001b[32m     16\u001b[39m instance_transforms_infer = {\n\u001b[32m     17\u001b[39m     k: instantiate(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m instance_tf_cfg.inference.items()\n\u001b[32m     18\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[39m, in \u001b[36minstantiate\u001b[39m\u001b[34m(config, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     _convert_ = config.pop(_Keys.CONVERT, ConvertMode.NONE)\n\u001b[32m    224\u001b[39m     _partial_ = config.pop(_Keys.PARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_partial_\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf.is_list(config):\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[32m    231\u001b[39m     config_copy = copy.deepcopy(config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:333\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    331\u001b[39m exclude_keys = \u001b[38;5;28mset\u001b[39m({\u001b[33m\"\u001b[39m\u001b[33m_target_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_convert_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_recursive_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m_partial_\u001b[39m\u001b[33m\"\u001b[39m})\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_target(node):\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     _target_ = \u001b[43m_resolve_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_Keys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m     kwargs = {}\n\u001b[32m    335\u001b[39m     is_partial = node.get(\u001b[33m\"\u001b[39m\u001b[33m_partial_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m partial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/.venv/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:139\u001b[39m, in \u001b[36m_resolve_target\u001b[39m\u001b[34m(target, full_key)\u001b[39m\n\u001b[32m    137\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[32m    138\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(target):\n\u001b[32m    141\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected a callable target, got \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(target).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInstantiationException\u001b[39m: Error locating target 'torchvision.transforms.v2.Compose', set env var HYDRA_FULL_ERROR=1 to see chained exception.\nfull_key: train.audio"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from src.datasets.collate import collate_fn\n",
    "\n",
    "datasets_cfg = OmegaConf.load(\"src/configs/datasets/onebatchtest.yaml\")\n",
    "instance_tf_cfg = OmegaConf.load(\n",
    "    \"src/configs/transforms/instance_transforms/example.yaml\"\n",
    ")\n",
    "\n",
    "instance_transforms_train = {\n",
    "    k: instantiate(v) for k, v in instance_tf_cfg.train.items()\n",
    "}\n",
    "\n",
    "instance_transforms_infer = {\n",
    "    k: instantiate(v) for k, v in instance_tf_cfg.inference.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15da5bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorchvision\u001b[49m -v)\n",
      "\u001b[31mNameError\u001b[39m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "print(torchvision -v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f5fe93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
