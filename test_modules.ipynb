{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c4622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/progphys/asr-hw/f8fff82d17f34cebbcb0db9b4c3801c6\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : smoke-test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/progphys/asr-hw/f8fff82d17f34cebbcb0db9b4c3801c6\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss_demo              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     steps_per_sec_demo [4] : (52.87368476709142, 8000.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Name            : smoke-test\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     hasNestedParams : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     note                : smoke\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     trainer|resume_from : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     audio               : 3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataframe           : 1 (17 bytes)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     histogram3d         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     images              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample         : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [ 8.6291738e-02  1.7193973e-01  3.3875823e-01]\n",
      " [ 1.7193973e-01  3.3875823e-01  6.3745725e-01]\n",
      " ...\n",
      " [-1.7185840e-01 -3.3860287e-01 -6.3720274e-01]\n",
      " [-8.6304612e-02 -1.7196518e-01 -3.3880684e-01]\n",
      " [ 1.3670491e-05  2.7340982e-05  5.4681965e-05]]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from src.logger.cometml import CometMLWriter\n",
    "logger = logging.getLogger(\"smoke\")\n",
    "project_config = {\"trainer\": {\"resume_from\": None}, \"note\": \"smoke\"}\n",
    "writer = CometMLWriter(\n",
    "    logger=logger,\n",
    "    project_config=project_config,\n",
    "    project_name=\"asr-hw\",\n",
    "    workspace=\"progphys\",\n",
    "    run_name=\"smoke-test\",\n",
    "    mode=\"online\",\n",
    ")\n",
    "\n",
    "writer.set_step(0, mode=\"demo\")\n",
    "writer.add_scalar(\"loss\", 1.0)\n",
    "\n",
    "writer.set_step(1, mode=\"demo\")\n",
    "writer.add_image(\"img\", (np.random.rand(32, 64) * 255).astype(np.uint8))\n",
    "\n",
    "sr = 16000\n",
    "t = torch.linspace(0, 1, sr)\n",
    "\n",
    "audio_3ch_torch = torch.stack([\n",
    "    torch.sin(2 * torch.pi * 220 * t),\n",
    "    torch.sin(2 * torch.pi * 440 * t),\n",
    "    torch.sin(2 * torch.pi * 880 * t),\n",
    "], dim=0) \n",
    "\n",
    "writer.set_step(2, mode=\"demo\")\n",
    "writer.add_audio(\"sine_3ch_torch\", audio_3ch_torch, sample_rate=sr)\n",
    "\n",
    "t_np = np.linspace(0, 1, sr, endpoint=False)\n",
    "audio_3ch_np = np.stack([\n",
    "    np.sin(2 * np.pi * 220 * t_np),\n",
    "    np.sin(2 * np.pi * 440 * t_np),\n",
    "    np.sin(2 * np.pi * 880 * t_np),\n",
    "], axis=1).astype(np.float32)   \n",
    "\n",
    "\n",
    "writer.set_step(3, mode=\"demo\")\n",
    "writer.add_audio(\"sine_3ch_numpy\", audio_3ch_np, sample_rate=sr)\n",
    "\n",
    "\n",
    "writer.set_step(4, mode=\"demo\")\n",
    "writer.add_audio(\"from_file_3ch\", \"test.wav\")\n",
    "\n",
    "writer.add_text(\"pred\", \"hello\")\n",
    "writer.add_histogram(\"h\", torch.randn(1000))\n",
    "\n",
    "writer.add_table(\"t\", pd.DataFrame({\"a\":[1,2], \"b\":[3,4]}))\n",
    "\n",
    "writer.exp.end()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3904b685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcd\n",
      "bbcccd\n"
     ]
    }
   ],
   "source": [
    "#check ctc decode\n",
    "\n",
    "from src.text_encoder.ctc_text_encoder import CTCTextEncoder\n",
    "\n",
    "model = CTCTextEncoder()\n",
    "fake_inds = torch.tensor([0, 2, 2, 0, 3, 3, 3, 0, 4], dtype=torch.long)\n",
    "print(model.ctc_decode(fake_inds))\n",
    "print(model.decode(fake_inds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78424582",
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t, p, cer_exp, wer_exp \u001b[38;5;129;01min\u001b[39;00m tests:\n\u001b[32m     14\u001b[39m     cer = calc_cer(t, p)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     wer = \u001b[43mcalc_wer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cer_exp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(cer - cer_exp) < eps, (t, p, cer, cer_exp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/EduMaterials/DL/DLA/HW2/src/metrics/utils.py:24\u001b[39m, in \u001b[36mcalc_wer\u001b[39m\u001b[34m(target_text, predicted_text)\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(predicted_words) == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1.0\u001b[39m\n\u001b[32m     23\u001b[39m dist = editdistance.eval(target_words,predicted_words)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdist\u001b[49m\u001b[43m/\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "from src.metrics.utils import calc_cer,calc_wer\n",
    "#chatgpt generate tests\n",
    "eps = 1e-6\n",
    "\n",
    "tests = [\n",
    "    (\"\", \"\", 0.0, 0.0),\n",
    "    (\"\", \"a\", 1.0, 1.0),\n",
    "    (\"abcd\", \"aecd\", 0.25, 1.0),\n",
    "    (\"abcd\", \"\", 1.0, 1.0),\n",
    "    (\"abcd\", \"abbcd\", 0.25, 1.0),\n",
    "    (\"a b c\", \"a b\", None, 1/3),\n",
    "    (\"a b\", \"a x b\", None, 0.5),\n",
    "]\n",
    "\n",
    "for t, p, cer_exp, wer_exp in tests:\n",
    "    cer = calc_cer(t, p)\n",
    "    wer = calc_wer(t, p)\n",
    "\n",
    "    if cer_exp is not None:\n",
    "        assert abs(cer - cer_exp) < eps, (t, p, cer, cer_exp)\n",
    "\n",
    "    if wer_exp is not None:\n",
    "        assert abs(wer - wer_exp) < eps, (t, p, wer, wer_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec22fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
