# Краткий отчёт по задаче

## 1. Воспроизведение модели

**Команды запуска**

* Обучение:

  * `python train.py -cn baseline.yaml`
* Инференс / оценка:

  * `python inference.py -cn inference.yaml`
---

## 2. Логи обучения и скорость

**Время обучения**

* Время одной эпохи: 55 минут
* Общее время обучения: 9 часов
* Используемые ресурсы (GPU/CPU, загрузка памяти): Использовалась RTX 3090, среднее использование памяти около 20 гб

**Динамика метрик**

* Train loss: падала примерно на 0.1 каждую эпоху
* Основная метрика (CER / WER / accuracy и т.д.): Также падала все время

Из-за использования агументаций скорость обучения была низкой, но при должном времени результат должен быть лучше

**Стабильность обучения**

* Были ли NaN / divergence: нет
* Поведение градиентов: Норма держалась стабильно

---

## 3. Обучение финальной модели

**Финальная конфигурация**

* Конфиг:conformer_beam_full_aug
* Количество эпох: 15

## 4. Проведённые эксперименты

**Архитектура**

Была реализована модель Сonformer без относительно позиционного экондера. Использовался стандартный абсолютный.


## 5. Что сработало / не сработало

**Сработало**

* Добавление BeamSearch немного улучшило все метрики

**Не сработало**

*Агументация слишком сильно замедляет обучение, непонятно насколько больше качества это даст

---
## 6. Основные сложности

* Долгое обучение 

---

## 7. Анализ графиков и экспериментов

Ссылка на cometML: https://www.comet.com/progphys/asr-hw/view/new/panels

